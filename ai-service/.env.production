# Production Environment Variables for AI Service
# These should be set in your deployment platform (Railway, Heroku, etc.)

# Flask Configuration
FLASK_ENV=production
FLASK_DEBUG=false
PORT=8000
HOST=0.0.0.0

# AI Model Configuration
HUGGING_FACE_TOKEN=your-hugging-face-token
MODEL_NAME=mistralai/Mistral-7B-Instruct-v0.1
MODEL_CACHE_DIR=/app/model_cache
MODEL_MAX_LENGTH=512
MODEL_TEMPERATURE=0.7

# Performance Configuration
MAX_WORKERS=4
WORKER_TIMEOUT=120
WORKER_CONNECTIONS=1000
KEEP_ALIVE=2

# Logging
LOG_LEVEL=INFO
LOG_FORMAT=json

# Security
CORS_ORIGINS=https://your-backend-api.railway.app
API_KEY_REQUIRED=false

# Resource Limits
MAX_MEMORY_MB=2048
MAX_CPU_PERCENT=80
REQUEST_TIMEOUT=30

# Monitoring
HEALTH_CHECK_INTERVAL=30
METRICS_ENABLED=true

# Cache Configuration
CACHE_ENABLED=true
CACHE_TTL=3600
CACHE_MAX_SIZE=1000